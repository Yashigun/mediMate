<div align="center">

# Meet Miffy!
  <img width="350" alt="image" src="https://github.com/user-attachments/assets/98653ea2-cff2-4015-9158-dfcaaf46f031" />
</div>

### Miffy is an AI-powered medical assistant platform that helps users check symptoms, get structured triage guidance, locate nearby care, and navigate their health journey â€” through a friendly, voice-enabled chatbot interface.

---

## Features

### ðŸ¤– AI Medical Chatbot (MediMate Bot)
- Powered by **Google Gemini 2.5 Flash** for fast, context-aware medical conversations
- **Conversational memory** â€” the full chat history is sent with every message so Gemini remembers prior symptoms, answers, and concerns across the session
- **Patient intake flow** â€” on first conversation, collects name, age, gender, weight, height, current medications, allergies, and prior surgeries before giving triage
- **Structured triage output** when symptoms are described:
  - **Severity** Â· **Immediate Need for Attention** Â· **See a Doctor If** Â· **Next Steps** Â· **Possible Conditions** Â· **Disclaimer**
- **Multilingual** â€” detects the language of each user message and replies in the same language (English, Hindi, Marathi, Urdu, Kannada, Telugu, Odia, Bhojpuri, and more)
- **Quick-prompt chips** on the welcome screen for one-tap symptom entry

### ðŸŽ™ï¸ Voice Input
- Click the mic button and speak your symptoms â€” no typing required
- Uses the browser's **MediaRecorder API** to capture audio locally
- Audio is sent to the backend where **Gemini transcribes it** (bypasses Chrome's SpeechRecognition which requires Google's speech servers)
- Live recording and transcribing status indicators with pulse animation

### ðŸ“„ Auto PDF Report Generation
- When the conversation ends (user says "bye", "thank you", or "thanks"), a **consultation report PDF downloads automatically**
- Report is generated by Gemini from the full chat history and includes:
  - Patient Information Â· Reason for Consultation Â· Symptoms Summary
  - Medical History Reported by Patient Â· Suggested Areas for Clinical Review Â· Follow-up Questions
- Built with **PDFKit** on the backend

### ðŸ—ºï¸ Nearby Hospitals & Pharmacies
- Interactive map powered by **OpenStreetMap & Overpass API**
- Detects your approximate location via GPS or IP geolocation fallback
- Shows hospitals, clinics, and pharmacies within a **5 km radius**
- Includes a legend and radius circle for clarity
- Falls back to prominent Delhi hospitals (AIIMS, Safdarjung, Apollo, Fortis, Apollo Pharmacy, MedPlus) if location detection fails

### ðŸš¨ Emergency SOS Button
- One-click emergency trigger from the navbar
- Detects location via GPS with IP-based fallback
- Shows a confirmation popup with a Google Maps link
- Auto-hides after a few seconds

---

## Architecture

**Services and ports:**

| Service | Path | Port | Purpose |
|---------|------|------|---------|
| Main Frontend | `frontend/` | Vite default | React 19 SPA â€” landing page, map, dashboard |
| Main Backend | `backend/` | 4000 | Express 5 + MongoDB (doctors, admin, uploads) |
| Auth Server | `backend/authServer/` | 5000 | JWT auth microservice (login / signup) |
| Chatbot Server | `MediMateBot/server/` | 8080 | Gemini 2.5 Flash â€” chat, transcribe, report |
| Chatbot Client | `MediMateBot/client/` | Vite default (HTTPS) | React chat UI |

**Chatbot API endpoints (`MediMateBot/server/server.js`):**

| Method | Endpoint | Purpose |
|--------|----------|---------|
| `POST` | `/chat` | Send message + history â†’ Gemini â†’ structured reply |
| `POST` | `/transcribe` | Send base64 audio â†’ Gemini â†’ transcript text |
| `POST` | `/report` | Send full history â†’ Gemini â†’ download PDF |

---

## Tech Stack

| Layer | Technologies |
|-------|-------------|
| **Chatbot Frontend** | React 19, Vite 7, Framer Motion, `@vitejs/plugin-basic-ssl` (HTTPS) |
| **Chatbot Backend** | Express 4, `@google/generative-ai`, PDFKit, CORS, dotenv |
| **Main Frontend** | React 19, Vite 7, Tailwind CSS 4, React Router 7, Framer Motion, Leaflet, Axios |
| **Main Backend** | Express 5, Mongoose / MongoDB, JWT + Bcrypt, Multer + Cloudinary, Joi |
| **AI Model** | Google Gemini 2.5 Flash |

---

## Installation

**Chatbot backend:**
```bash
cd MediMateBot/server
npm install
```

**Chatbot frontend:**
```bash
cd MediMateBot/client
npm install
```

**Main frontend:**
```bash
cd frontend
npm install
```

**Auth backend:**
```bash
cd backend/authServer
npm install
```

**Main backend:**
```bash
cd backend
npm install
```

---

## Environment Variables

**`MediMateBot/server/.env`**
```env
GEMINI_API_KEY=your_google_gemini_api_key
```

**`backend/authServer/.env`**
```env
PORT=5000
MONGO_URI=your_mongodb_uri
JWT_SECRET=your_jwt_secret_key
```

**`backend/.env`**
```env
MONGODB_URI=your_mongodb_uri
CLOUDINARY_NAME=your_cloudinary_name
CLOUDINARY_API_KEY=your_cloudinary_api_key
CLOUDINARY_SECRET_KEY=your_cloudinary_secret
PORT=4000
```

---

## Running the Project

All services run independently â€” each needs its own terminal.

**Chatbot backend** (port 8080):
```bash
cd MediMateBot/server
npm start
```

**Chatbot frontend** (HTTPS, Vite default port):
```bash
cd MediMateBot/client
npm run dev
```
> Opens on `https://localhost:5173`. On first visit Chrome will show a self-signed certificate warning â€” click **Advanced â†’ Proceed to localhost**. HTTPS is required for microphone access.

**Main frontend:**
```bash
cd frontend
npm run dev
```

**Auth backend** (port 5000):
```bash
cd backend/authServer
npm run dev
```

**Main backend** (port 4000):
```bash
cd backend
npm run server
```

---

## Voice Input â€” How It Works

The mic button uses the browser's native **MediaRecorder API** (no external libraries):

1. User clicks mic â†’ browser requests microphone permission
2. Audio is recorded locally as a `webm` blob
3. User clicks mic again to stop recording
4. Blob is converted to base64 and `POST`ed to `/transcribe`
5. The backend sends the audio to **Gemini 2.5 Flash** for transcription
6. The transcript is returned and automatically sent as a chat message

> **Note:** Voice input requires Chrome and microphone permission. The chatbot frontend must be running on HTTPS (handled automatically by the Vite dev config).

---

## PDF Report â€” How It Works

When the user says `"bye"`, `"thank you"`, or `"thanks"` at the end of a session:

1. The full conversation history is `POST`ed to `/report`
2. Gemini generates a structured clinical summary in plain text
3. The backend renders it as a **PDF using PDFKit** with a report ID, timestamp, and disclaimer
4. The PDF downloads automatically in the browser

---

## Chatbot UI

The MediMate Bot UI is styled to match the main Miffy landing page:

- **Dark navy-to-teal gradient** background matching the landing page hero
- **Glassmorphism header** with bot avatar, gradient title text, and live "Online" status
- **Welcome screen** with quick-prompt chips for one-tap symptom entry
- **User messages** â€” teal gradient pill bubbles (right-aligned)
- **Bot messages** â€” white frosted glass cards with soft shadow (left-aligned)
- **Unified pill input bar** â€” text field, mic button, and send button in one rounded container
- **Slide-in message animations** consistent with landing page motion style
